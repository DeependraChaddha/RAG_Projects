{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn9slDU3Cu/YI6bBE2UADo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeependraChaddha/RAG_Projects/blob/main/RAG_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ENVIRONMENT SETUP"
      ],
      "metadata": {
        "id": "xpGgBBOidBND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF3BDzFHcn9N"
      },
      "outputs": [],
      "source": [
        "#INSTALLING REQUIRED PACKAGES\n",
        "!pip install langchain_community tiktoken langchain_openai langchainhub chromadb langchain youtube-transcript-api pytub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SETTING LANGSMITH ENVIRONMENT\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]='true'\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]='https://api.smith.langchain.com'\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=#YOUR_API_KEY\n"
      ],
      "metadata": {
        "id": "TnMoD8VBfg08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OPENAI API KEY\n",
        "os.environ[\"OPENAI_API_KEY\"]=#YOUR_API_KEY"
      ],
      "metadata": {
        "id": "4WwME7rdf-Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ROUTING"
      ],
      "metadata": {
        "id": "YrXcYyVGgXtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOGICAL ROUTING"
      ],
      "metadata": {
        "id": "W_5NkOaagk9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MAKING REQUIRED IMPORTS\n",
        "from typing import Literal\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#DataModel\n",
        "class RouteQuery(BaseModel): #Routes user query to most suitable datasource\n",
        "#datasource attribute/field can only take one of the 3 values\n",
        "  datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(#Field function used to add metadata or customize fields of models\n",
        "      ...,#This is to let PyDantic know that this field cannot be omitted\n",
        "                                                                      description=\"Given a user question choose which datasource would be most relevant for answering their question\",\n",
        "    )#This class gives the format in which the llm will answer the query it is provided with in the RAG chain\n",
        "\n",
        "#LLM with function call\n",
        "llm=ChatOpenAI(model=\"gpt-3.5-turbo-0125\",temperature=0)\n",
        "structured_llm=llm.with_structured_output(RouteQuery) #This asks the llm to provide answer in the structure/format specified by class defined above(inherited from BaseModel class of Pydantic)\n",
        "\n",
        "#Prompt\n",
        "system=\"\"\"You are an expert at routing a user question to the appropriate data source.\n",
        "\n",
        "Based on the programming language the question is referring to, route it to the relevant data source.\"\"\"\n",
        "\n",
        "prompt=ChatPromptTemplate.from_messages([\n",
        "    (\"system\",system),\n",
        "    (\"human\",\"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "#Define Router\n",
        "router=prompt|structured_llm #This chain takes the prompt and pipes it to the llm which gives an output structured according to RouteQuery"
      ],
      "metadata": {
        "id": "QCL_3i1Rgm0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"\"\"Why doesn't the following code work:\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
        "prompt.invoke(\"french\")\n",
        "\"\"\"\n",
        "#INVOKING THE ROUTER CHAIN\n",
        "result= router.invoke({\"question\":question})"
      ],
      "metadata": {
        "id": "Bzy7tOtKutKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "1_lsKGpwu8nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.datasource"
      ],
      "metadata": {
        "id": "D1bv2BQGu-0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_route(result):\n",
        "  if \"python_docs\" in result.datasource.lower():\n",
        "    return \"chain for python_docs\"\n",
        "  elif \"json_docs\" in result.datasource.lower():\n",
        "    return \"chain for json_docs\"\n",
        "  else:\n",
        "    return \"golang_docs\"\n",
        "\n",
        "from langchain.runnables import RunnableLambda\n",
        "#standardize function to be useful in Langchain pipeline architecture\n",
        "full_chain=router|RunnableLamda(choose_route)"
      ],
      "metadata": {
        "id": "oPyWJ5w6vURG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INVOKE FULL CHAIN\n",
        "full_chain.invoke({\"question\":question})"
      ],
      "metadata": {
        "id": "w2EhFHTKwtVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEMANTIC ROUTING"
      ],
      "metadata": {
        "id": "bYLMWRnQw7Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MAKE ALL REQUIRED IMPORTS\n",
        "from langchain.utils.math import cosine_similarity\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "zp1urDsxw-03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 PROMPTS"
      ],
      "metadata": {
        "id": "t1LIZJ4CyFui"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}