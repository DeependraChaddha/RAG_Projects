{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEu1QWmN5JBVk3JEuSSjFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeependraChaddha/RAG_Projects/blob/main/RAG_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##QUERY CONSTRUCTION"
      ],
      "metadata": {
        "id": "vJAj5SFksOZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query Construction refers to taking the query as natural language and converting it into domain-specific language for the selected data source. This is done for better retrieval"
      ],
      "metadata": {
        "id": "Pbo41HN3sTuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This following code is to fetch metadata from youtube transcripts of videos"
      ],
      "metadata": {
        "id": "erXC5FvqzlrL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxLvuhKSsKNp"
      },
      "outputs": [],
      "source": [
        "#make imports\n",
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "\n",
        "docs=YoutubLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=pbAd8O1Lvm4\",\n",
        "    add_video_info=True,\n",
        ").load()\n",
        "\n",
        "docs[0].metadata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make schema for structured search queries"
      ],
      "metadata": {
        "id": "qgHGAk5W2duG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make imports\n",
        "import datetime\n",
        "from typing import Literal, Optional, Tuple\n",
        "fromlangchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "\n",
        "#Defining class for giving structured to output of llm\n",
        "class TutorialSearch(BaseModel):\n",
        "  ###Searches over database of tutorial videos about a software library###\n",
        "\n",
        "  content_search:str= Field(\n",
        "      ...,\n",
        "      description=\"Similarity search query applied to video transcripts.\",\n",
        "  )\n",
        "  title_search:str = Field(\n",
        "      ...,\n",
        "      description=(\"Alternate version of the content search query to apply to video titles. \"\n",
        "                 \"Should be succinct and only include key words that could be in a video \"\n",
        "                 \"title.\"),\n",
        "  )\n",
        "  #Following attributes are optional\n",
        "  min_view_count:Optional[int]= Field(\n",
        "      None,\n",
        "      description=\"Minimum view count filter, inclusive. Only use if explicitly specified.\",\n",
        "  )\n",
        "  max_view_count:Optional[int]=Field(\n",
        "      None,\n",
        "      description=\"Maximum view count filter, exclusive. Only use if explicitly specified.\"\n",
        "  )\n",
        "  earliest_publish_date: Optional[datetime.date] = Field(\n",
        "      None,\n",
        "      description=\"Earliest publish date filter, inclusive. Only use if explicitly specified.\",\n",
        "  )\n",
        "  latest_publish_date: Optional[datetime.date] = Field(\n",
        "      None,\n",
        "      description=\"Latest publish date filter, exclusive. Only use if explicitly specified.\",\n",
        "  )\n",
        "  min_length_sec: Optional[int] = Field(\n",
        "      None,\n",
        "      description=\"Minimum video length in seconds, inclusive. Only use if explicitly specified.\",\n",
        "  )\n",
        "  max_length_sec: Optional[int] = Field(\n",
        "      None,\n",
        "      description=\"Maximum video length in seconds, exclusive. Only use if explicitly specified.\",\n",
        "  )\n",
        "\n",
        "\n",
        "  def pretty_print(self) -> None:\n",
        "    #Only prints the attribute if the attribute value is not none and different from their default value\n",
        "    for field in self.__fields__:\n",
        "      if getattr(self,field) is not None and getattr(self, field)!=getattr(self.__fields__[field],\"default\",None):\n",
        "        print(f\"{field}:{getattr(self,field)}\")\n"
      ],
      "metadata": {
        "id": "vF_iPQEz20DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make RAG chain"
      ],
      "metadata": {
        "id": "1G1TMcBZaFB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#Make templates\n",
        "system=\"\"\"You are an expert at converting user questions into database queries. \\\n",
        "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
        "Given a question, return a database query optimized to retrieve the most relevant results.\n",
        "\n",
        "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
        "#make prompt from template\n",
        "prompt=ChatPromptTemplate.from_messages(\n",
        "    [(\"system\",system),(\"human\",{question})]\n",
        ")\n",
        "llm= ChatOpenAI(model=\"gpt-3.5-turbo-0125\",temperature=0)\n",
        "structured_llm=llm.with_structured_output(TutorialSearch)\n",
        "query_analyzer=prompt|structure_llm\n"
      ],
      "metadata": {
        "id": "c7aOpzPpaHRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Various Queries"
      ],
      "metadata": {
        "id": "n20H_JOscqzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke({\"question\":\"rag from scratch\"}).pretty_print()\n"
      ],
      "metadata": {
        "id": "dOovVHsAb1j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyxer.invoke({\"question\":\"videos on chat langchain published in 2023\"}).pretty_print()"
      ],
      "metadata": {
        "id": "ddYG_g1DcVMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke({\"question\":\"videos that are focused on the topic of chat langchain that are published before 2024\"}).pretty_print()"
      ],
      "metadata": {
        "id": "h0nwmo9jcojg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke({\"question\":\"how to use multi-modal models in an agent, only videos under 5 minutes\"}).pretty_print()"
      ],
      "metadata": {
        "id": "g4fEWnUkdB6h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}